# SVD 是怎么被“想出来”的？——从一个朴素问题出发

你有没有见过这样的公式？

M=UΣVTM=UΣVT

看起来挺简洁，对吧？但当你翻开教材，发现这背后藏着一堆正交矩阵、奇异值、特征向量……瞬间头大。

我每次看到 SVD，都忍不住想：这玩意儿到底是怎么被“想出来”的？是某个数学家喝多了咖啡，突然梦见上帝说：“听着，所有矩阵都能拆成三步走……”

今天，我们不背公式，不套定理。我们要还原 SVD 的“发明”过程——从一个最朴素的问题出发：**一个矩阵，到底对向量做了什么？**

---

## 一、矩阵左乘 = 沿坐标轴的伸缩（从最简单例子开始）

我们从一个最简单的 2×22×2 对角矩阵入手：

D=[3001]D=[3001]

取任意向量 x=[x1x2]x=[x1x2]，左乘后得到：

Dx=[3x1x2]Dx=[3x1x2]

这意味着：**输入向量在标准基方向 e1=(1,0)Te1=(1,0)T 和 e2=(0,1)Te2=(0,1)T 上被独立拉伸**——xx 方向放大 3 倍，yy 方向不变。

这个例子揭示了矩阵左乘的本质：**线性变换 = 对输入空间的各个方向进行伸缩（可能还混合）**。
而对角矩阵之所以“干净”，是因为它恰好以标准基为伸缩方向，没有混合。

但现实中的矩阵通常不是对角的。那么问题来了：**非对角矩阵是否也能找到自己的“伸缩方向”？**

---

## 二、EVD：方阵的“主伸缩方向”与秩的含义

考虑一个对称方阵：

A=[2112]A=[2112]

我们寻找那些**被 AA 作用后只伸缩、不转向**的向量 vv，即满足：

Av=λvAv=λv

这就是**特征方程**，其中 λλ 是特征值，vv 是对应的特征向量。

对上面的 AA，解得两组解：

* λ1=3λ1=3，对应 v1=[11]v1=[11]
* λ2=1λ2=1，对应 v2=[1−1]v2=[1−1]

将这两个向量单位化（归一化），得到标准正交基：

q1=1√2[11],q2=1√2[1−1]q1=12[11],q2=12[1−1]

把它们拼成正交矩阵 Q=[q1,q2]Q=[q1,q2]，则 QTQ=IQTQ=I。
由于 Aqi=λiqiAqi=λiqi 对每个列都成立，我们可以把所有等式合写为：

AQ=QΛ⇒A=QΛQTAQ=QΛ⇒A=QΛQT

其中

Λ=[3001]Λ=[3001]

这就是**特征值分解（EVD）**。它告诉我们：**任何可对角化的方阵，本质上只是在一组特定正交方向上做独立伸缩**。

---

### 满秩 vs 低秩：不只是数学，更是能力

一个 n×nn×n 矩阵的“能力”取决于它有多少个非零特征值。

* **满秩矩阵**：比如

  A=[2112]A=[2112]

  有两个非零特征值（3 和 1），秩为 2。它能对**任意方向**的输入产生非零输出——换句话说，它可以“操控”整个 2D 空间。
* **低秩矩阵**：比如

  B=[1111]B=[1111]

  特征值为 2 和 0，秩为 1。它只能在方向 [11][11] 上拉伸，而在垂直方向 [1−1][1−1] 上输出恒为零。**无论你输入什么，结果永远落在一条直线上**。

在深度学习中，这种差异至关重要：

* **满秩变换**（如初始权重）具有最大表达能力，能响应任意输入变化；
* **低秩更新**（如微调时的 ΔWΔW）则表明：模型真正需要调整的，往往只是少数几个“敏感方向”。

这正是 **LoRA**（Low-Rank Adaptation）有效的核心原因：我们不需要改动整个高维权重矩阵，只需在低维子空间中微调，就能高效适配新任务。

但 EVD 有一个致命限制：**它只适用于方阵**。一旦矩阵是“长方形”的，比如 M∈Rn×mM∈Rn×m 且 n≠mn≠m，特征方程 Mv=λvMv=λv 就因维度不匹配而失去意义。

于是，我们必须回答一个更一般的问题：**非方阵如何描述其“伸缩行为”？**

---

## 三、SVD：为非方阵找到“跨空间的主方向”

面对 M∈Rn×mM∈Rn×m，我们放弃“输入输出方向相同”的执念，转而问：

> 是否存在输入空间的一组标准正交基 {v1,…,vm}{v1,…,vm} 和输出空间的一组标准正交基 {u1,…,un}{u1,…,un}，使得
>
> Mvi=σiui(i=1,…,r=min(n,m))Mvi=σiui(i=1,…,r=min(n,m))

这个等式是我们希望达成的目标：**第 ii 个输入主方向 vivi，只激发第 ii 个输出主方向 uiui，放大 σiσi 倍**。

我们按拉伸强度从大到小排序：σ1≥σ2≥⋯≥σr≥0σ1≥σ2≥⋯≥σr≥0。

更一般的表示是

MV=UΣMV=UΣ

后面我们可以知道VV是正交矩阵，所以上式两边都右乘VTVT，就可以得到常见的 SVD 的形式了

MVVT=MVV−1=M=UΣVTMVVT=MVV−1=M=UΣVT

### 3.1 以最强方向 σ1σ1 为例

回归正题，我们该如何计算 σiσi呢？我们以最强方向，即 σ1σ1为最大值的情况为例。

假设存在单位向量 v1v1 和 u1u1，使得：

Mv1=σ1u1,∥v1∥=∥u1∥=1.Mv1=σ1u1,‖v1‖=‖u1‖=1.

两边取范数，得：

∥Mv1∥=∥σ1u1∥=σ1.‖Mv1‖=‖σ1u1‖=σ1.

因此，σ1σ1 就是 MM 在单位输入下能产生的最大输出长度。
换句话说，σ1σ1 是如下优化问题的解：

σ1=max∥v∥=1∥Mv∥.σ1=max‖v‖=1‖Mv‖.

由于范数非负，等价于最大化其平方：

σ21=max∥v∥=1∥Mv∥2=max∥v∥=1vT(MTM)v.σ12=max‖v‖=1‖Mv‖2=max‖v‖=1vT(MTM)v.

### 3.2 计算奇异值和右奇异矩阵 V

记 A=MTMA=MTM。矩阵 AA 是 m×mm×m 实对称矩阵，且对任意 vv 有 vTAv≥0vTAv≥0，故 AA 半正定。记 AA 的特征值按非增序排列为 λ1≥λ2≥⋯≥λm≥0λ1≥λ2≥⋯≥λm≥0，对应的标准正交特征向量为 q1,…,qmq1,…,qm，即

Aqi=λiqiAqi=λiqi

瑞利商的极值性质表明(原理推导见本节末尾）：

max∥v∥=1vTAv=λ1,max‖v‖=1vTAv=λ1,

且最大值在 v=q1v=q1 处取得。更一般地，对 k=1,…,mk=1,…,m，

max∥v∥=1v⊥q1,…,qk−1vTAv=λk,max‖v‖=1v⊥q1,…,qk−1vTAv=λk,

在 v=qkv=qk 处取得。说人话就是，第k 大的值就是λkλk，而且是在v=qkv=qk时可以得到。

所以

σ2i=max∥v∥=1vT(MTM)v=λii=1,…,m,σi2=max‖v‖=1vT(MTM)v=λii=1,…,m,

则 σi=√λi,σ1≥σ2≥⋯≥σm≥0σi=λi,σ1≥σ2≥⋯≥σm≥0，且

vi=qivi=qi

至此，我们成功求解了矩阵 V和奇异值矩阵ΣΣ

> **瑞利商性质**：对实对称矩阵 AA，定义其**瑞利商**为
>
> RA(c)=cTAccTc,c≠0.RA(c)=cTAccTc,c≠0.
>
> 当 ∥c∥=1‖c‖=1 时，RA(c)=cTAcRA(c)=cTAc。
> 设 AA 的特征值按非增序排列为 λ1≥λ2≥⋯≥λm≥0λ1≥λ2≥⋯≥λm≥0，对应的标准正交特征向量为 q1,…,qmq1,…,qm，即
>
> Aqi=λiqi,qTiqj=δij.Aqi=λiqi,qiTqj=δij.
>
> 瑞利商的极值性质表明：
>
> max∥c∥=1cTAc=λ1,max‖c‖=1cTAc=λ1,
>
> 且最大值在 c=q1c=q1 处取得。更一般地，对 k=1,…,mk=1,…,m，
>
> max∥c∥=1c⊥q1,…,qk−1cTAc=λk,max‖c‖=1c⊥q1,…,qk−1cTAc=λk,
>
> 在 c=qkc=qk 处取得。
> 因此，令
>
> σi=√λi,ci=qi,i=1,…,m,σi=λi,ci=qi,i=1,…,m,
>
> 则 σ1≥σ2≥⋯≥σm≥0σ1≥σ2≥⋯≥σm≥0，且
>
> ∥Mci∥2=cTiAci=λi=σ2i.‖Mci‖2=ciTAci=λi=σi2.

### 3.3 构造左奇异矩阵

令 r=rank(M)r=rank⁡(M)。由于 rank(M)=rank(MTM)rank⁡(M)=rank⁡(MTM)，有 σi>0σi>0 当且仅当 i≤ri≤r。

对每个 i=1,…,ri=1,…,r，根据最前面的定义Mvi=σiuiMvi=σiui，我们有

ui=1σiMvi.ui=1σiMvi.

至此就可算出对应的σi,vi,uiσi,vi,ui。我们会发现求得的 uiui也是基坐标，彼此正交：

∥ui∥=1σi∥Mvi∥=1σi⋅σi=1,‖ui‖=1σi‖Mvi‖=1σi⋅σi=1,

且

Mvi=σiui.Mvi=σiui.

对 i≠j≤ri≠j≤r，有

uTiuj=1σiσjvTiMTMvj=1σiσjvTi(σ2jvj)=σj⋅vTivj=0,uiTuj=1σiσjviTMTMvj=1σiσjviT(σj2vj)=σj⋅viTvj=0,

故 {u1,…,ur}{u1,…,ur} 是 RnRn 中的标准正交向量组。

前面计算的uiui是与vivi一一对应的，但是当 r<nr<n时，剩下的uiui该如何计算呢？我们会发现存在 n−rn−r 维子空间

U⊥={x∈Rn∣∣uTix=0, ∀i=1,…,r}.U⊥={x∈Rn|uiTx=0, ∀i=1,…,r}.

在 U⊥U⊥ 中任取一组标准正交基 {ur+1,…,un}{ur+1,…,un}，则最终的左奇异矩阵为

U=[u1,…,un]∈Rn×nU=[u1,…,un]∈Rn×n

为正交矩阵。

### 3.4 拼装 SVD

令

* V=[v1,…,vm]∈Rm×mV=[v1,…,vm]∈Rm×m，
* Σ∈Rn×mΣ∈Rn×m 为对角矩阵，其对角元为 σ1,…,σrσ1,…,σr，其余元素为 0。

由 Mvi=σiuiMvi=σiui 对 i=1,…,ri=1,…,r 成立，且对 i>ri>r 有 σi=0σi=0，可得矩阵等式

MV=UΣ.MV=UΣ.

由于 VV 正交（VTV=ImVTV=Im），右乘 VTVT 得

M=UΣVT.M=UΣVT.

---

## 结语

SVD 并非凭空定义的数学魔术，而是为了解决“**非方阵如何描述伸缩**”这一朴素问题，从对角矩阵 → EVD → 跨空间推广，一步步自然推导出的必然结果。

当你再看到 M=UΣVTM=UΣVT，请记住：
**它只是在说——先转一下，再拉伸，再转一下。**
而这，就是所有线性变换最干净的表达方式。

* [SVD 是怎么被“想出来”的？——从一个朴素问题出发](#svd-%E6%98%AF%E6%80%8E%E4%B9%88%E8%A2%AB%E6%83%B3%E5%87%BA%E6%9D%A5%E7%9A%84%E4%BB%8E%E4%B8%80%E4%B8%AA%E6%9C%B4%E7%B4%A0%E9%97%AE%E9%A2%98%E5%87%BA%E5%8F%91)
* [一、矩阵左乘 = 沿坐标轴的伸缩（从最简单例子开始）](#%E4%B8%80%E7%9F%A9%E9%98%B5%E5%B7%A6%E4%B9%98--%E6%B2%BF%E5%9D%90%E6%A0%87%E8%BD%B4%E7%9A%84%E4%BC%B8%E7%BC%A9%E4%BB%8E%E6%9C%80%E7%AE%80%E5%8D%95%E4%BE%8B%E5%AD%90%E5%BC%80%E5%A7%8B)
* [二、EVD：方阵的“主伸缩方向”与秩的含义](#%E4%BA%8Cevd%E6%96%B9%E9%98%B5%E7%9A%84%E4%B8%BB%E4%BC%B8%E7%BC%A9%E6%96%B9%E5%90%91%E4%B8%8E%E7%A7%A9%E7%9A%84%E5%90%AB%E4%B9%89)
* [满秩 vs 低秩：不只是数学，更是能力](#%E6%BB%A1%E7%A7%A9-vs-%E4%BD%8E%E7%A7%A9%E4%B8%8D%E5%8F%AA%E6%98%AF%E6%95%B0%E5%AD%A6%E6%9B%B4%E6%98%AF%E8%83%BD%E5%8A%9B)
* [三、SVD：为非方阵找到“跨空间的主方向”](#%E4%B8%89svd%E4%B8%BA%E9%9D%9E%E6%96%B9%E9%98%B5%E6%89%BE%E5%88%B0%E8%B7%A8%E7%A9%BA%E9%97%B4%E7%9A%84%E4%B8%BB%E6%96%B9%E5%90%91)
* [3.1 以最强方向 σ1\sigma\_1 为例](#tid-h2rhh2)
* [3.2 计算奇异值和右奇异矩阵 V](#tid-8bpnfw):[nuts坚果](https://zhongshanyuan.com)
* [3.3 构造左奇异矩阵](#tid-Ec8swe)
* [3.4 拼装 SVD](#tid-NYawS4)
* [结语](#%E7%BB%93%E8%AF%AD)

\_\_EOF\_\_

marsggbo - **本文链接：** [https://github.com/marsggbo/p/19180904](https://github.com)
- **关于博主：** 评论和私信会在第一时间回复。或者[直接私信](https://github.com)我。
- **版权声明：** 私信联系获得许可后方可转载文章。
- **声援博主：** 如果您觉得文章对您有帮助，可以点击文章右下角**【[推荐](javascript:void(0);)】**一下。
